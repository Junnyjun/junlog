# 최적의 성능을 위한 하드웨어 선택 가이드

### 최적의 성능을 위한 하드웨어 선택 가이드

카프카의 성능은 하드웨어 자원에 크게 의존하며, 본문은 각 자원별로 구체적인 선택 기준을 제시합니다.

* 디스크 처리량과 용량: 카프카는 모든 메시지를 디스크에 저장합니다. 따라서 디스크의 쓰기 처리량(Throughput)이 전체 성능의 병목이 될 수 있습니다. 본문은 높은 처리량이 필요한 경우 SSD를 권장하며, 비용 대비 효율을 고려할 때 다수의 HDD를 RAID 0이나 JBOD(Just a Bunch of Disks) 구조로 구성하여 입출력을 분산시키는 전략을 상세히 설명합니다.
* 메모리와 페이지 캐시: 카프카의 실제 성능 비결은 운영체제의 '페이지 캐시'를 적극적으로 활용하는 데 있습니다. 메시지는 디스크에 직접 읽고 쓰는 것이 아니라 메모리상의 페이지 캐시를 거치기 때문에, 시스템 메모리가 넉넉할수록 디스크 I/O를 줄이고 지연 시간을 획기적으로 낮출 수 있습니다. 본문은 애플리케이션 힙(Heap) 메모리보다 OS 페이지 캐시를 위해 메모리를 비워두는 것이 더 효율적임을 강조합니다.
* 네트워크와 CPU: 프로듀서와 컨슈머가 쏟아내는 엄청난 데이터를 감당하기 위해 기가비트 이더넷 이상의 네트워크 대역폭이 필수적입니다. CPU는 메시지의 압축이나 해제 시 중요하게 작용하지만, 다른 요소들에 비하면 상대적으로 병목 현상이 덜 발생하는 자원으로 묘사됩니다.

***

### 운영체제 환경의 세밀한 튜닝

리눅스 환경에서 카프카 브로커가 안정적으로 수천 개의 연결을 처리하기 위해 반드시 조정해야 할 설정들입니다.

* 파일 디스크립터(File Descriptors): 카프카는 각 파티션과 네트워크 연결마다 파일을 사용합니다. 기본 설정값은 대규모 트래픽을 감당하기에 너무 작으므로, 본문은 이 값을 100,000 이상으로 대폭 상향할 것을 권장합니다.
* 가상 메모리 설정: 스왑(Swap) 메모리를 과도하게 사용하면 성능이 급격히 저하됩니다. 본문은 `vm.swappiness` 값을 매우 낮게 설정하여 메모리 부족 시에도 가급적 페이지 캐시를 유지하고 실제 RAM을 사용하도록 유도하는 방법을 설명합니다.
* 더티 페이지 관리: 메모리에 써진 데이터가 실제 디스크로 옮겨지는 간격(`vm.dirty_ratio`)을 조정하여, 시스템이 한꺼번에 많은 디스크 쓰기를 수행하며 멈추는 현상을 방지해야 합니다.

***

### 카프카의 새로운 관리 체계: 주키퍼와 KRaft

본문은 카프카의 메타데이터를 관리하는 두 가지 방식의 차이점을 상세히 다룹니다.

* 전통적인 주키퍼(ZooKeeper) 방식: 카프카는 오랫동안 클러스터의 상태와 파티션 정보를 주키퍼에 의존해왔습니다. 2장에서는 주키퍼 앙상블(Ensemble)을 구성할 때 홀수 대수(3, 5대 등)로 구성해야 하는 이유와 정족수(Quorum) 원리를 상세히 설명합니다.
* 새로운 시대의 KRaft 방식: 2판에서는 주키퍼 없이 카프카 자체적으로 클러스터를 관리하는 KRaft 모드에 대해서도 비중 있게 다룹니다. 이는 아키텍처를 단순화하고 수만 개의 파티션을 효율적으로 관리할 수 있게 해주는 카프카의 중요한 진화 방향입니다.

***

### 핵심적인 브로커 설정 파라미터들

실제 `server.properties` 파일에서 서비스 안정성을 결정짓는 주요 설정값들에 대한 설명입니다.

* 데이터 보관 정책(Retention): `log.retention.hours`는 데이터를 얼마나 오래 보관할지 결정합니다. 또한 `log.retention.bytes`를 통해 용량 기준으로도 보관량을 제어할 수 있습니다. 본문은 이 두 설정이 동시에 적용될 때 어떤 기준이 우선되는지에 대한 로직을 상세히 기술합니다.
* 메시지 크기 제한: `message.max.bytes` 설정은 브로커가 수용할 수 있는 최대 메시지 크기를 결정합니다. 이 값은 프로듀서와 컨슈머의 설정과도 일치해야 하며, 너무 크게 설정할 경우 네트워크 지연과 메모리 압박을 줄 수 있음을 경고합니다.
* 파티션 관리와 자동 생성: `num.partitions`는 새 토픽이 생성될 때의 기본 파티션 개수입니다. 본문은 운영 환경에서 실수를 방지하기 위해 토픽 자동 생성 기능(`auto.create.topics.enable`)을 비활성화하는 것을 권장하는 실무적인 조언을 담고 있습니다.

***

### 클러스터 구성과 다중 가용 영역 배치

데이터의 안정성을 보장하기 위해 브로커를 어떻게 물리적으로 배치해야 하는지에 대한 내용입니다.

* 브로커 ID와 유일성: 클러스터 내의 모든 브로커는 고유한 ID를 가져야 하며, 이는 나중에 서버를 교체하더라도 동일하게 유지되어야 파티션 데이터를 보존할 수 있습니다.
* 랙 인식(Rack Awareness): 실무에서 매우 중요한 설정입니다. 본문은 `broker.rack` 설정을 통해 카프카가 서로 다른 랙이나 가용 영역(AZ)에 복제본(Replica)을 분산 배치하도록 유도하는 방법을 설명합니다. 이를 통해 특정 랙의 전원이 나가거나 스위치 장애가 발생해도 전체 서비스가 중단되지 않는 강력한 내결함성을 확보할 수 있습니다.
