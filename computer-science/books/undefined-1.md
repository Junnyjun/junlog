# 📙 카프카핵심가이드

### 데이터 메시징의 복잡성과 발행/구독 모델의 필연적 등장

현대적인 데이터 처리 환경에서 가장 먼저 직면하는 난관은 끊임없이 생성되는 데이터를 어떻게 효율적으로 이동시키느냐 하는 문제입니다. 1장은 이 파이프라인의 관리 문제가 비즈니스의 사활을 결정하는 핵심 요소임을 강조합니다.

* 포인트 투 포인트 아키텍처의 한계와 고통: 초기에는 데이터 생성지와 목적지를 직접 연결하는 단순한 구조를 택합니다. 하지만 시스템이 확장되면서 연결의 수는 기하급수적으로 늘어납니다. 예를 들어, 한 서비스의 메트릭 데이터를 대시보드에도 보내고, 로그 분석 시스템에도 보내며, 장기 보관용 데이터베이스에도 보내야 하는 상황이 오면 관리해야 할 연결선이 엉키기 시작합니다. 이를 본문에서는 '스파게티 아키텍처'로 묘사하며, 하나의 시스템 변경이 수많은 연결된 파이프라인에 영향을 주어 유지보수를 불가능하게 만든다고 지적합니다.
* 중앙 집중형 발행/구독 시스템의 도입: 이러한 혼란을 해결하기 위해 발행자(데이터 생성자)가 특정 수신자를 지정하지 않고, 데이터를 공통된 통로로 던지는 방식이 제안됩니다. 구독자(데이터 소비)는 이 통로에서 자신에게 필요한 데이터만 골라 가져가게 됩니다. 이 모델은 송신자와 수신자 사이의 결합도를 완전히 제거하여, 시스템 전체의 유연성을 획기적으로 높여줍니다.

***

### 카프카의 핵심 단위인 메시지와 배치의 상세 메커니즘

카프카 시스템 내부에서 데이터가 처리되는 방식은 효율성과 성능에 최적화되어 설계되었습니다.

* 메시지의 구조와 키의 역할: 카프카에서 다루는 가장 작은 데이터 단위는 메시지입니다. 메시지는 바이트 배열 형태의 페이로드를 가지며, 이는 카프카가 데이터의 형식을 가리지 않고 무엇이든 담을 수 있음을 의미합니다. 특히 메시지에는 '키'라고 불리는 선택적인 메타데이터가 포함됩니다. 이 키는 단순히 정보를 담는 것을 넘어, 데이터를 특정 파티션에 할당하는 로직을 결정하는 데 쓰입니다. 이를 통해 연관된 데이터를 항상 같은 파티션에 배치하여 처리 순서를 보장할 수 있습니다.
* 배치를 통한 성능 극대화: 카프카는 메시지를 하나씩 전송하지 않고 '배치'라는 묶음 단위로 처리합니다. 같은 토픽과 파티션으로 향하는 메시지들을 모아서 한꺼번에 전송함으로써 네트워크 통신의 오버헤드를 비약적으로 줄입니다. 본문은 이 과정에서 처리량과 지연 시간 사이의 트레이드오프가 발생함을 명시합니다. 배치가 커질수록 전체적인 데이터 처리량은 늘어나지만, 개별 메시지가 전달되는 데 걸리는 시간은 조금 더 길어질 수 있습니다.

***

### 데이터 일관성을 위한 스키마의 중요성

본문은 데이터의 형태가 변하더라도 시스템 전체가 멈추지 않도록 하는 스키마의 역할을 강조합니다.

* 스키마 정의와 아파치 아브로: 메시지가 단순히 바이트 배열이라면, 이를 읽는 쪽에서는 데이터가 무엇을 의미하는지 알기 어렵습니다. 따라서 데이터의 구조를 명확히 정의하는 스키마가 필요합니다. 본문은 유연하고 강력한 스키마 도구로 아파치 아브로(Apache Avro)를 소개하며, 이를 통해 발행자와 구독자가 서로 독립적으로 진화할 수 있는 환경을 제공한다고 설명합니다. 스키마는 데이터 파편화를 막고 전사적인 데이터 품질을 유지하는 핵심 도구가 됩니다.

***

### 토픽과 파티션을 이용한 수평적 확장의 원리

카프카가 어떻게 단일 서버의 한계를 넘어 대규모 트래픽을 감당하는지에 대한 물리적, 논리적 구조 설명입니다.

* 토픽이라는 논리적 분류: 메시지는 토픽이라는 카테고리에 저장됩니다. 이는 데이터베이스의 테이블과 같은 개념으로, 데이터를 성격에 따라 분리하는 역할을 합니다.
* 파티션을 통한 데이터 분산 저장: 하나의 토픽은 하나 이상의 파티션으로 쪼개집니다. 메시지는 파티션의 끝부분에 추가되는 방식으로만 저장(Append-only)됩니다. 이 파티션들은 클러스터 내의 여러 브로커에 분산되어 배치되는데, 바로 이 구조 덕분에 카프카는 수평적 확장이 가능해집니다. 파티션 내에서는 메시지가 도착한 순서대로 읽히는 것이 보장되어, 데이터 스트림의 흐름을 정확히 파악할 수 있게 해줍니다.

***

### 프로듀서와 컨슈머의 유기적인 동작과 컨슈머 그룹

카프카 클라이언드들이 데이터를 주고받는 상세한 동작 방식입니다.

* 프로듀서의 책임: 프로듀서는 데이터를 생성해 카프카 브로커로 보냅니다. 기본적으로 부하 분산을 위해 데이터를 여러 파티션에 균등하게 나눠 보내지만, 특정 비즈니스 로직에 따라 파티셔너를 설정해 특정 파티션을 선택할 수도 있습니다.
* 컨슈머 그룹과 병렬 처리: 컨슈머는 토픽을 구독해 데이터를 읽습니다. 특히 여러 컨슈머가 하나의 '그룹'을 형성하는 기능이 핵심인데, 그룹 내의 컨슈머들은 토픽의 파티션들을 서로 나누어 맡습니다. 이를 통해 대량의 데이터를 여러 서버에서 동시에 처리할 수 있는 병렬성을 확보합니다. 또한, 컨슈머는 자신이 읽은 위치인 '오프셋'을 기록함으로써 장애가 발생해 재시작하더라도 중단된 지점부터 정확히 작업을 이어갈 수 있습니다.

***

### 브로커와 클러스터의 관리 및 데이터 보존 원칙

카프카의 하드웨어적 구성과 데이터의 생명 주기에 대한 본문의 설명입니다.

* 브로커와 컨트롤러의 역할: 개별 카프카 서버인 브로커는 메시지를 수신하여 디스크에 저장하고, 요청에 따라 데이터를 전달합니다. 여러 브로커가 모여 하나의 클러스터를 이루며, 그중 선출된 하나의 브로커가 '컨트롤러'가 되어 파티션 할당과 브로커 상태를 관리하는 지휘자 역할을 수행합니다.
* 데이터 보존(Retention) 정책: 카프카는 메시지를 영구적으로 저장하는 대신, 설정된 기간이나 용량에 따라 보관합니다. 예를 들어 '7일 동안 보관'하거나 '1GB까지 보관'하도록 설정할 수 있으며, 이 기준을 넘어서면 오래된 데이터부터 자동으로 삭제됩니다. 이러한 보존 정책은 카프카를 단순한 전달 도구가 아닌 신뢰성 있는 저장소로 만들어줍니다.

***

### 링크드인의 실제 사례와 카프카의 탄생 의의

본문은 카프카가 탄생하게 된 실무적인 배경을 아주 구체적으로 다룹니다.

* 링크드인의 절박함: 당시 링크드인은 엄청난 양의 사용자 활동 데이터와 시스템 지표를 실시간으로 수집하고 분석해야 했습니다. 하지만 기존의 로그 수집 도구나 ETL 방식, 메시지 큐들은 확장성과 실시간성이라는 두 마리 토끼를 잡기에 역부족이었습니다.
* 새로운 패러다임의 제시: 링크드인 개발팀은 데이터를 정적인 파일이 아닌, 실시간으로 끊임없이 흐르는 이벤트 스트림으로 바라보는 시스템을 구축했습니다. 이것이 카프카의 시작이며, 오늘날 기업의 모든 데이터를 실시간으로 연결하는 '중앙 신경망'이자 '스트리밍 플랫폼'으로서의 정체성을 확립하게 된 배경입니다.
