# 📙 카프카핵심가이드

### 발행/구독 모델의 필연성과 기존 시스템의 붕괴

데이터 중심 아키텍처에서 가장 먼저 마주하는 과제는 '어떻게 데이터를 보낼 것인가'입니다. 1장은 데이터 파이프라인이 단순한 기술적 도구를 넘어 비즈니스의 민첩성을 결정하는 핵심 요소임을 강조하며 시작합니다.

* 포인트 투 포인트 방식의 한계: 초기에는 서비스 간에 데이터를 직접 연결하여 전송합니다. 하지만 서비스가 늘어날수록 연결선은 기하급수적으로 증가하며, 이는 관리 불가능한 '스파게티 아키텍처'를 초래합니다. 시스템 하나를 수정할 때마다 연결된 수십 개의 파이프라인을 검토해야 하는 고통이 뒤따릅니다.
* 데이터의 파편화와 중복: 동일한 데이터가 여러 곳으로 전송되면서 시스템마다 서로 다른 프로토콜(HTTP, FTP 등)과 데이터 형식(JSON, XML 등)을 사용하게 됩니다. 이는 전사적인 데이터 일관성을 해치는 주범이 됩니다.
* 카프카의 접근법: 카프카는 모든 데이터를 중앙으로 집중시키고 필요한 곳에서 가져가게 함으로써 시스템 간의 의존성을 완전히 제거(Decoupling)합니다.

***

### 카프카의 탄생 배경과 링크드인의 혁신

카프카는 링크드인 내부에서 발생하는 폭발적인 실시간 데이터를 처리하기 위해 탄생했습니다. 당시 존재하던 기술들로는 해결할 수 없는 명확한 문제들이 있었기 때문입니다.

* 기존 메시징 시스템과의 차이: 액티브MQ와 같은 기존 도구들은 데이터 보관 능력이 부족했고, 하둡과 같은 분석 도구는 실시간성이 떨어졌습니다. 링크드인은 이 두 세계의 장점을 모두 가진 시스템이 필요했습니다.
* 이벤트 스트림이라는 관점: 카프카 개발진은 데이터를 '과거의 정적인 기록'이 아닌, '지금 이 순간에도 끊임없이 흐르는 이벤트의 연속'으로 정의했습니다. 이 철학적 전환이 카프카를 단순한 큐(Queue)가 아닌 분산 스트리밍 플랫폼으로 만들었습니다.

***

### 카프카를 지탱하는 핵심 기술 단위와 상세 구조

카프카의 강력한 성능과 유연성은 정교하게 설계된 내부 구성 요소들로부터 나옵니다.

* 메시지와 배치: 메시지는 데이터의 최소 단위이며 바이트 배열 형태로 저장되어 형식에 구애받지 않습니다. 네트워크 오버헤드를 줄이기 위해 메시지들을 묶어서 전송하는 '배치' 처리는 카프카가 높은 처리량을 유지하는 핵심 비결입니다.
* 토픽과 파티션: 데이터를 구분하는 논리적 단위인 토픽은 여러 개의 파티션으로 나뉩니다. 파티션은 여러 서버에 분산 저장되어 수평적 확장을 가능하게 하며, 각 파티션 내에서는 메시지의 순서가 엄격히 보장됩니다.
* 프로듀서와 컨슈머 그룹: 프로듀서는 데이터를 생성해 토픽으로 밀어 넣습니다. 컨슈머는 데이터를 읽는데, 특히 '컨슈머 그룹'이라는 개념을 통해 여러 컨슈머가 파티션을 나누어 병렬 처리하도록 함으로써 대규모 트래픽을 감당합니다.
* 브로커와 클러스터: 개별 서버인 브로커들이 모여 클러스터를 이룹니다. 클러스터는 데이터를 여러 서버에 복제(Replication)하여 저장함으로써, 특정 서버에 장애가 발생해도 데이터 유실 없이 서비스를 지속할 수 있는 고가용성을 제공합니다.

***

### 카프카가 현대 아키텍처의 표준이 된 이유

책의 전반부에서 강조하는 카프카의 독보적인 강점은 다음과 같습니다.

* 디스크 기반의 영속성: 데이터를 메모리가 아닌 디스크에 안전하게 기록합니다. 설정에 따라 며칠, 몇 달간 데이터를 보관할 수 있어 과거 데이터를 재처리하거나 사고 발생 시 복구하는 능력이 탁월합니다.
* 다중 구독 시스템: 하나의 데이터 스트림을 실시간 분석 팀, 보안 팀, 장기 보관 팀이 동시에 각각의 목적으로 사용할 수 있습니다. 이는 데이터 활용의 효율성을 극대화합니다.
* 선형적 확장성: 데이터 양이 늘어나면 단순히 브로커(서버)를 추가하는 것만으로 시스템 성능을 거의 무한히 확장할 수 있습니다.
