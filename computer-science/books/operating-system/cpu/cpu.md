# 실시간 CPU 스케줄링

### 실시간 CPU 스케줄링

실시간 운영체제의 CPU 스케줄링은 특별한 문제를 수반합니다. 일반적으로 소프트 실시간 시스템과 하드 실시간 시스템을 구분할 수 있습니다. 소프트 실시간 시스템은 중요한 실시간 프로세스가 언제 스케줄링될지에 대한 보장을 제공하지 않습니다. 단지 비필수 프로세스보다 우선권을 부여할 뿐입니다. 반면 하드 실시간 시스템은 더 엄격한 요구 사항을 가집니다. 작업은 마감 기한 내에 서비스되어야 하며, 마감 기한이 지난 후의 서비스는 전혀 서비스가 없는 것과 같습니다. 이 섹션에서는 소프트 및 하드 실시간 운영체제에서 프로세스 스케줄링과 관련된 몇 가지 문제를 살펴봅니다.

***

#### 지연 시간 최소화

실시간 시스템의 이벤트 기반 특성을 고려해 봅시다. 시스템은 일반적으로 실시간으로 이벤트가 발생하기를 기다립니다. 이벤트는 타이머 만료와 같은 소프트웨어에서 발생하거나 원격 제어 차량이 장애물에 접근하는 것을 감지하는 것과 같은 하드웨어에서 발생할 수 있습니다. 이벤트가 발생하면 시스템은 가능한 한 빨리 응답하고 서비스를 제공해야 합니다. 이벤트 발생부터 서비스 제공까지 걸리는 시간을 \*\*이벤트 지연 시간(event latency)\*\*이라고 합니다.

일반적으로 다양한 이벤트는 다른 지연 시간 요구 사항을 가집니다. 예를 들어, 잠금 방지 제동 시스템의 지연 시간 요구 사항은 3\~5밀리초일 수 있습니다. 이는 바퀴가 미끄러지는 것을 처음 감지한 시점부터 잠금 방지 제동을 제어하는 시스템이 상황에 응답하고 제어하는 데 3\~5밀리초가 걸린다는 의미입니다. 더 오래 걸리는 응답은 차량이 통제 불능 상태가 될 수 있습니다. 반면, 항공기의 레이더를 제어하는 임베디드 시스템은 몇 초의 지연 시간을 허용할 수 있습니다.

두 가지 유형의 지연 시간이 실시간 시스템의 성능에 영향을 미칩니다:

1. 인터럽트 지연 시간(interrupt latency)
2. 디스패치 지연 시간(dispatch latency)

인터럽트 지연 시간은 인터럽트가 CPU에 도착한 시점부터 인터럽트를 처리하는 루틴이 시작될 때까지의 기간을 나타냅니다. 인터럽트가 발생하면 운영체제는 먼저 실행 중인 명령어를 완료하고 발생한 인터럽트 유형을 결정해야 합니다. 그런 다음 특정 인터럽트 서비스 루틴(ISR)을 사용하여 인터럽트를 처리하기 전에 현재 프로세스의 상태를 저장해야 합니다. 이 작업들을 수행하는 데 필요한 총 시간을 인터럽트 지연 시간이라고 합니다. 실시간 운영체제는 실시간 작업이 즉각적인 주의를 받도록 인터럽트 지연 시간을 최소화하는 것이 중요합니다. 하드 실시간 시스템의 경우 인터럽트 지연 시간은 시스템의 엄격한 요구 사항을 충족하기 위해 단순히 최소화되어야 하는 것을 넘어, 제한되어야 합니다.

스케줄링 디스패처가 하나의 프로세스를 중지하고 다른 프로세스를 시작하는 데 필요한 시간을 디스패치 지연 시간이라고 합니다. 실시간 작업에 CPU에 대한 즉각적인 접근을 제공하려면 실시간 운영체제는 이 지연 시간도 최소화해야 합니다. 디스패치 지연 시간을 낮게 유지하는 가장 효과적인 기술은 선점형 커널을 제공하는 것입니다. 하드 실시간 시스템의 경우 디스패치 지연 시간은 일반적으로 몇 마이크로초 단위로 측정됩니다.

***

#### 우선순위 기반 스케줄링

실시간 운영체제의 가장 중요한 특징은 실시간 프로세스가 CPU를 필요로 하는 즉시 응답하는 것입니다. 결과적으로 실시간 운영체제의 스케줄러는 선점 기능을 갖춘 우선순위 기반 알고리즘을 지원해야 합니다. 우선순위 기반 스케줄링 알고리즘은 각 프로세스에 중요도에 따라 우선순위를 할당합니다. 현재 CPU에서 실행 중인 프로세스는 더 높은 우선순위의 프로세스가 실행 가능해지면 선점됩니다.

선점형, 우선순위 기반 스케줄링 알고리즘은 일반적으로 자세히 논의됩니다. Linux, Windows, Solaris 운영체제의 소프트 실시간 스케줄링 기능은 이러한 시스템의 예시를 제공합니다. 이러한 각 시스템은 실시간 프로세스에 가장 높은 스케줄링 우선순위를 할당합니다.

하드 실시간 시스템은 실시간 작업이 마감 기한 요구 사항에 따라 서비스될 것을 추가로 보장해야 하며, 이러한 보장을 위해서는 추가적인 스케줄링 기능이 필요합니다.

스케줄링될 프로세스에 대한 특정 특성을 정의해야 합니다. 먼저, 프로세스는 주기적인 것으로 간주됩니다. 즉, 일정한 간격(주기)으로 CPU를 필요로 합니다. 주기적인 프로세스가 CPU를 획득하면 고정된 처리 시간 t, CPU가 서비스를 제공해야 하는 마감 기한 d, 그리고 주기 p를 가집니다. 스케줄러는 이러한 특성을 활용하여 프로세스의 마감 기한 또는 속도 요구 사항에 따라 우선순위를 할당할 수 있습니다.

***

#### 속도 단조 스케줄링

속도 단조 스케줄링(Rate-Monotonic Scheduling) 알고리즘은 선점을 통한 정적 우선순위 정책을 사용하여 주기적인 작업을 스케줄링합니다. 낮은 우선순위 프로세스가 실행 중이고 더 높은 우선순위 프로세스가 실행 가능해지면, 낮은 우선순위 프로세스를 선점합니다. 시스템에 진입할 때 각 주기적 작업에는 주기에 반비례하여 우선순위가 할당됩니다. 주기가 짧을수록 우선순위는 높아지고, 주기가 길수록 우선순위는 낮아집니다.

이 스케줄링 방식은 최적의 방식입니다. 즉, 이 알고리즘으로 스케줄링할 수 없는 프로세스 집합은 정적 우선순위를 할당하는 다른 어떤 알고리즘으로도 스케줄링할 수 없습니다. 그러나 속도 단조 스케줄링은 CPU 활용률이 제한적이라는 한계가 있습니다. N개의 프로세스를 스케줄링할 때 최악의 CPU 활용률은 `N(2^(1/N) - 1)`입니다.

***

#### 최단 마감 기한 우선 스케줄링

최단 마감 기한 우선(Earliest-Deadline-First, EDF) 스케줄링은 마감 기한에 따라 동적으로 우선순위를 할당합니다. 마감 기한이 빠를수록 우선순위가 높고, 마감 기한이 늦을수록 우선순위가 낮습니다. EDF 정책에서 프로세스가 실행 가능해지면 시스템에 마감 기한 요구 사항을 알려야 합니다. 새로 실행 가능한 프로세스의 마감 기한을 반영하여 우선순위를 조정해야 할 수 있습니다. 이는 우선순위가 고정된 속도 단조 스케줄링과 다릅니다.

EDF 스케줄링은 속도 단조 알고리즘과 달리 프로세스가 주기적이어야 하거나 버스트당 일정한 CPU 시간을 요구할 필요가 없습니다. 프로세스는 실행 가능해질 때 스케줄러에 마감 기한을 알려야 할 뿐입니다. EDF 스케줄링의 매력은 이론적으로 최적이라는 점입니다. 이론적으로 각 프로세스가 마감 기한 요구 사항을 충족하고 CPU 활용률이 100%가 되도록 프로세스를 스케줄링할 수 있습니다. 그러나 실제로는 프로세스 간의 컨텍스트 전환 및 인터럽트 처리 비용 때문에 이러한 수준의 CPU 활용률을 달성하는 것은 불가능합니다.

***

#### 비례 배분 스케줄링

\*\*비례 배분 스케줄러(Proportional Share Schedulers)\*\*는 모든 애플리케이션에 T개의 공유를 할당하여 작동합니다. 애플리케이션은 N개의 시간 공유를 받을 수 있으며, 이는 애플리케이션이 총 프로세서 시간의 N/T를 차지함을 보장합니다.

비례 배분 스케줄러는 애플리케이션이 할당된 시간 공유를 받도록 보장하기 위해 승인 제어 정책과 함께 작동해야 합니다. 승인 제어 정책은 특정 수의 공유를 요청하는 클라이언트가 충분한 공유를 사용할 수 있는 경우에만 허용합니다.

***

#### POSIX 실시간 스케줄링

POSIX 표준은 실시간 컴퓨팅을 위한 확장 기능인 POSIX.1b도 제공합니다. 여기서는 실시간 스레드 스케줄링과 관련된 POSIX API의 일부를 다룹니다. POSIX는 실시간 스레드에 대해 두 가지 스케줄링 클래스를 정의합니다:

* SCHED\_FIFO: FIFO 큐를 사용하여 선입선출 정책에 따라 스레드를 스케줄링합니다. 그러나 동일 우선순위 스레드 간에는 타임 슬라이싱이 없습니다. 따라서 FIFO 큐의 가장 높은 우선순위 실시간 스레드는 종료되거나 블록될 때까지 CPU를 할당받습니다.
* SCHED\_RR: 라운드 로빈 정책을 사용합니다. SCHED\_FIFO와 유사하지만 동일 우선순위 스레드 간에 타임 슬라이싱을 제공합니다.

POSIX는 스케줄링 정책을 가져오고 설정하는 두 가지 함수를 지정합니다:

* `pthread_attr_getschedpolicy(pthread_attr_t *attr, int *policy)`
* `pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy)`
