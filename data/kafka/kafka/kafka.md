# Kafka?

**Apache Kafka**는 **분산형 스트리밍 플랫폼**으로, 대규모 데이터를 실시간으로 처리하는 데 최적화된 메시지 브로커 시스템입니다. Kafka는 **데이터 스트리밍**, **데이터 파이프라인**, **이벤트 소싱** 및 **분산 로그 저장소** 등 다양한 용도로 사용되며, 주로 실시간 데이터 처리와 관련된 환경에서 많이 활용됩니다. Kafka의 작동 원리와 구동 방식을 이해하면, 왜 Kafka가 대규모 실시간 데이터 처리에 최적화되어 있는지 알 수 있습니다.

<img src="../../../.gitbook/assets/file.excalidraw (1).svg" alt="" class="gitbook-drawing">

## Data Replication

Kafka에서 데이터 복제(Replication)는 고가용성과 데이터 안전성을 보장하기 위한 핵심 기능입니다. 각 **파티션**은 하나의 리더(Leader)와 여러 개의 팔로워(Follower)로 구성됩니다.&#x20;

프로듀서는 리더 파티션에 데이터를 쓰고, 팔로워 파티션은 이 데이터를 복제합니다. 이를 통해 **데이터 손실**이나 **브로커 장애** 상황에서 팔로워가 리더로 승격되어 시스템이 지속적으로 운영될 수 있습니다.

싱크(Sync)는 데이터를 복제할 때 사용되는 **동기화 메커니즘**입니다. 리더가 데이터를 쓰면, 설정에 따라 일부 또는 모든 팔로워가 해당 데이터를 수신하고 저장한 후 이를 리더에게 확인(Sync Acknowledgement)합니다. Kafka는 **ACK** 설정(acks=0, 1, all)을 통해, 팔로워가 데이터를 얼마나 복제한 후에 프로듀서에게 쓰기 성공을 알릴지 결정할 수 있습니다.

이러한 복제와 싱크 구조는 Kafka가 **데이터의 내구성**과 **시스템 가용성**을 보장하는 데 중요한 역할을 합니다.

<img src="../../../.gitbook/assets/file.excalidraw.svg" alt="" class="gitbook-drawing">

위와 같이 브로커가 장애가 발생해도 리더 파티션의 지위를 넘겨 받아 유실되지 않도록 해준다.\
데이터가 중요한 데이터의 경우 복제 개수를 높게(3) 설정하여 최대 2개의 브로커가 다운되더라도 안정적으로 유지할 수 있도록 해야한다.

### Controller

컨트롤러(Controller)는 클러스터 내에서 **파티션 리더의 선출** 및 **브로커 장애 감지**와 같은 중요한 작업을 관리하는 역할을 합니다. Kafka 클러스터에는 하나의 컨트롤러가 존재하며, 주로 **ZooKeeper**와 통신하여 리더 파티션을 지정하고 브로커 장애가 발생했을 때 **리더 파티션을 재배치**하는 등의 작업을 수행합니다.&#x20;

컨트롤러는 클러스터의 안정성과 고가용성을 유지하는 중요한 컴포넌트입니다.

#### Data Lifecycle

**데이터 삭제**는 주로 **로그 세그먼트(Log Segment) 압축**과 보관 정책(Retention Policy)에 의해 관리됩니다. Kafka는 데이터를 수동으로 삭제하지 않고, 설정된 보관 정책에 따라 자동으로 관리합니다.&#x20;

1. **시간 기반 보관(Retention Time)**: 메시지가 저장된 지 일정 시간이 지나면 Kafka가 자동으로 해당 데이터를 삭제합니다. 예를 들어, `retention.ms` 설정에 따라 데이터를 지정된 시간 이후에 삭제합니다.
2. **크기 기반 보관(Retention Size)**: 토픽 또는 파티션의 크기가 설정된 한계를 초과하면 오래된 데이터를 삭제합니다. `retention.bytes` 설정에 따라 일정 크기 이상의 데이터를 삭제하여 저장 공간을 확보합니다.

이 두 방식은 **데이터의 보존 기간**이나 **저장 용량**에 맞춰 데이터를 효율적으로 관리할 수 있도록 도와줍니다.

#### Consumer Offset

**컨슈머 오프셋**은 각 컨슈머가 **Kafka 토픽**의 데이터를 어디까지 읽었는지 추적하는 데 사용됩니다. 오프셋을 적절히 관리하면, 컨슈머가 중단되거나 재시작되었을 때 **중복 없이 이어서 데이터를 처리**할 수 있습니다.

컨슈머 오프셋은 기본적으로 **Kafka 내부의 특별한 토픽**인 `__consumer_offsets`에 저장됩니다. 이 토픽은 모든 오프셋 정보를 기록하며, Kafka 브로커가 이를 관리합니다. 컨슈머가 데이터를 읽으면, 주기적으로 또는 명시적으로 **커밋(commit)** 명령을 통해 오프셋을 저장할 수 있습니다.

1. **자동 커밋(Auto Commit)**: 설정된 주기에 따라 오프셋이 자동으로 커밋됩니다. (`enable.auto.commit=true`)
2. **수동 커밋(Manual Commit)**: 컨슈머 애플리케이션에서 명시적으로 오프셋을 커밋하는 방식입니다. 이는 데이터를 완전히 처리한 후에 커밋하여 **정확한 데이터 처리 보장**이 가능합니다.

이렇게 저장된 오프셋을 통해 컨슈머는 재시작 후에도 마지막으로 처리된 데이터 위치를 기억할 수 있습니다.

#### Coordinator

코디네이터(Coordinator)는 **컨슈머 그룹**을 관리하고, 컨슈머 오프셋을 조정하는 중요한 역할을 담당하는 컴포넌트입니다. Kafka의 컨슈머 그룹은 여러 컨슈머가 같은 그룹에 속해 있을 때, 각 컨슈머가 **특정 파티션**을 나눠서 처리하게 되는데, 이를 효율적으로 관리하는 것이 바로 코디네이터입니다.

1. **컨슈머 그룹 관리**: 컨슈머가 그룹에 가입하거나 나갈 때, 이를 감지하고 각 컨슈머에게 적절한 파티션을 할당합니다.
2. **오프셋 관리**: 컨슈머가 처리한 메시지의 오프셋을 **\_\_consumer\_offsets** 토픽에 저장하고, 컨슈머가 재시작하거나 장애가 발생했을 때 해당 오프셋을 기반으로 복구를 돕습니다.
3. **리밸런싱(Rebalancing)**: 컨슈머 그룹 내에서 구성원이 변경되거나 파티션이 추가되면, 코디네이터는 파티션을 다시 할당하는 **리밸런싱**을 수행하여 작업을 고르게 분배합니다.

코디네이터는 **컨슈머 그룹의 리더**로서, 파티션 할당과 오프셋 관리 등 컨슈머의 정상 동작을 조정하는 역할을 수행합니다.

